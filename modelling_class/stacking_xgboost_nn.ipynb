{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking binding classification with XGBoost and NN stacked\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "Stacking xgboost and NN predictions in a meta estimator.\n",
    "\n",
    "----\n",
    "\n",
    "- Cross validation using all data.\n",
    "\n",
    "- Using all observations (all species, </=/> values too)\n",
    "\n",
    "- simple one-hot encoding scheme for all categorical variables (species, hla type/subtypes,sequence)\n",
    "\n",
    "- This is the best i can do now\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 670 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5004)\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "os.environ['THEANO_FLAGS']='device=gpu1'\n",
    "\n",
    "#my functions\n",
    "sys.path.append('../')\n",
    "from utils import load_all_data,my_xgb_cv_predict,my_xgb_fit_predict,my_keras_cv_predict,my_keras_fit_predict,plot_roc\n",
    "\n",
    "#go to working dir\n",
    "work_dir='/data/data1/ribli/mhc/'\n",
    "os.chdir(work_dir)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,y_train,y_train_c=load_all_data(\n",
    "    hla_representation='one-hot',\n",
    "    species_representation='one-hot',\n",
    "    seq_representation='one-hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "### Get xgboost CV predictions on train data, and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.837028\teval-auc:0.811929\n",
      "[500]\ttrain-auc:0.990155\teval-auc:0.933122\n",
      "[1000]\ttrain-auc:0.996481\teval-auc:0.934676\n",
      "Stopping. Best iteration:\n",
      "[1224]\ttrain-auc:0.997585\teval-auc:0.934770\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.835189\teval-auc:0.817997\n",
      "[500]\ttrain-auc:0.990345\teval-auc:0.932652\n",
      "Stopping. Best iteration:\n",
      "[755]\ttrain-auc:0.994691\teval-auc:0.933318\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.837461\teval-auc:0.815366\n",
      "[500]\ttrain-auc:0.990445\teval-auc:0.933074\n",
      "[1000]\ttrain-auc:0.996677\teval-auc:0.934935\n",
      "Stopping. Best iteration:\n",
      "[978]\ttrain-auc:0.996531\teval-auc:0.935068\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.855848\teval-auc:0.842424\n",
      "[500]\ttrain-auc:0.990589\teval-auc:0.937817\n",
      "[1000]\ttrain-auc:0.996746\teval-auc:0.938814\n",
      "Stopping. Best iteration:\n",
      "[1086]\ttrain-auc:0.997222\teval-auc:0.938882\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.836416\teval-auc:0.809455\n",
      "[500]\ttrain-auc:0.990432\teval-auc:0.934084\n",
      "Stopping. Best iteration:\n",
      "[688]\ttrain-auc:0.993965\teval-auc:0.934969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model params\n",
    "params = {'max_depth':20,\n",
    "         'eta':0.1,\n",
    "         'min_child_weight':5,\n",
    "         'colsample_bytree':1,\n",
    "         'subsample':1,\n",
    "         'silent':1,\n",
    "         'objective': \"binary:logistic\",\n",
    "         'eval_metric': 'auc',\n",
    "         'nthread':8}\n",
    "\n",
    "xgb_train_pred=my_xgb_cv_predict(params,X_train,y_train_c,n_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119040 samples, validate on 13227 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_loss improved from inf to 0.40322, saving model to best_model\n",
      "3s - loss: 0.4179 - val_loss: 0.4032\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss improved from 0.40322 to 0.36684, saving model to best_model\n",
      "3s - loss: 0.3122 - val_loss: 0.3668\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 0.36684 to 0.34443, saving model to best_model\n",
      "3s - loss: 0.2758 - val_loss: 0.3444\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss improved from 0.34443 to 0.33257, saving model to best_model\n",
      "3s - loss: 0.2515 - val_loss: 0.3326\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss improved from 0.33257 to 0.32562, saving model to best_model\n",
      "3s - loss: 0.2296 - val_loss: 0.3256\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "3s - loss: 0.2109 - val_loss: 0.3459\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "3s - loss: 0.1932 - val_loss: 0.3437\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_loss did not improve\n",
      "3s - loss: 0.1763 - val_loss: 0.3557\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 00008: early stopping\n",
      "3s - loss: 0.1613 - val_loss: 0.3719\n",
      "Train on 119040 samples, validate on 13227 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_loss improved from inf to 0.38771, saving model to best_model\n",
      "3s - loss: 0.4203 - val_loss: 0.3877\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss improved from 0.38771 to 0.34667, saving model to best_model\n",
      "3s - loss: 0.3171 - val_loss: 0.3467\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 0.34667 to 0.33674, saving model to best_model\n",
      "3s - loss: 0.2810 - val_loss: 0.3367\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss did not improve\n",
      "3s - loss: 0.2570 - val_loss: 0.3742\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss did not improve\n",
      "3s - loss: 0.2354 - val_loss: 0.3444\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "3s - loss: 0.2158 - val_loss: 0.3368\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "3s - loss: 0.1976 - val_loss: 0.3589\n",
      "Train on 119040 samples, validate on 13227 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_loss improved from inf to 0.39484, saving model to best_model\n",
      "3s - loss: 0.4166 - val_loss: 0.3948\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss improved from 0.39484 to 0.34914, saving model to best_model\n",
      "3s - loss: 0.3126 - val_loss: 0.3491\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 0.34914 to 0.32117, saving model to best_model\n",
      "3s - loss: 0.2768 - val_loss: 0.3212\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss did not improve\n",
      "3s - loss: 0.2510 - val_loss: 0.3222\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss did not improve\n",
      "3s - loss: 0.2287 - val_loss: 0.3368\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "3s - loss: 0.2099 - val_loss: 0.3343\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "3s - loss: 0.1924 - val_loss: 0.3443\n",
      "Train on 119040 samples, validate on 13227 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_loss improved from inf to 0.36598, saving model to best_model\n",
      "3s - loss: 0.4185 - val_loss: 0.3660\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss improved from 0.36598 to 0.33261, saving model to best_model\n",
      "3s - loss: 0.3124 - val_loss: 0.3326\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 0.33261 to 0.32677, saving model to best_model\n",
      "3s - loss: 0.2756 - val_loss: 0.3268\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss did not improve\n",
      "3s - loss: 0.2506 - val_loss: 0.3331\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss did not improve\n",
      "3s - loss: 0.2278 - val_loss: 0.3375\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "3s - loss: 0.2082 - val_loss: 0.3504\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "3s - loss: 0.1891 - val_loss: 0.3435\n",
      "Train on 119041 samples, validate on 13227 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_loss improved from inf to 0.38435, saving model to best_model\n",
      "3s - loss: 0.4156 - val_loss: 0.3843\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss improved from 0.38435 to 0.34908, saving model to best_model\n",
      "3s - loss: 0.3114 - val_loss: 0.3491\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 0.34908 to 0.33342, saving model to best_model\n",
      "3s - loss: 0.2745 - val_loss: 0.3334\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss did not improve\n",
      "3s - loss: 0.2493 - val_loss: 0.3420\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss did not improve\n",
      "3s - loss: 0.2264 - val_loss: 0.3405\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "3s - loss: 0.2080 - val_loss: 0.3552\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: early stopping\n",
      "3s - loss: 0.1903 - val_loss: 0.3798\n"
     ]
    }
   ],
   "source": [
    "#create a very simple model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#create model creator\n",
    "def get_model(input_dim):\n",
    "    \"\"\"Creates Keras model needed.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input_dim,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#predict CV\n",
    "nn_train_pred=my_keras_cv_predict(get_model,X_train,y_train_c,n_folds=5,patience=3,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create stacked inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_stacked=np.column_stack([X_train,xgb_train_pred,nn_train_pred])\n",
    "\n",
    "#save them for the future\n",
    "np.save('class_stacked_x_train',X_train_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction with xgb on the stacked inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.928707\teval-auc:0.924539\n",
      "Stopping. Best iteration:\n",
      "[146]\ttrain-auc:0.942384\teval-auc:0.938189\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.928192\teval-auc:0.930280\n",
      "Stopping. Best iteration:\n",
      "[59]\ttrain-auc:0.940537\teval-auc:0.941310\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.929270\teval-auc:0.926162\n",
      "Stopping. Best iteration:\n",
      "[264]\ttrain-auc:0.943223\teval-auc:0.939412\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.929884\teval-auc:0.927427\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-auc:0.942014\teval-auc:0.939714\n",
      "\n",
      "Will train until eval error hasn't decreased in 200 rounds.\n",
      "[0]\ttrain-auc:0.928310\teval-auc:0.931126\n",
      "Stopping. Best iteration:\n",
      "[72]\ttrain-auc:0.941047\teval-auc:0.941833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth':3,\n",
    "         'eta':0.1,\n",
    "         'min_child_weight':5,\n",
    "         'colsample_bytree':1,\n",
    "         'subsample':1,\n",
    "         'silent':1,\n",
    "         'objective': \"binary:logistic\",\n",
    "         'eval_metric': 'auc',\n",
    "         'nthread':8}\n",
    "\n",
    "xgb_stacked_train_pred=my_xgb_cv_predict(params,X_train_stacked,y_train_c,n_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "def bootstrap_auc(y_c,y_pred,N=100):\n",
    "    \"\"\"Bootstrap the AUC score.\"\"\"\n",
    "    scores=[]\n",
    "    for i in xrange(N):\n",
    "        res_y=resample(np.column_stack([y_c,y_pred]))\n",
    "        scores.append(roc_auc_score(res_y[:,0],res_y[:,1]))\n",
    "        \n",
    "    print 'Score is :', '%.4f' % np.mean(scores),\n",
    "    print '+-','%.4f' % np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is : 0.9392 +- 0.0006\n"
     ]
    }
   ],
   "source": [
    "bootstrap_auc(y_train_c,xgb_stacked_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.939167728263\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAF+CAYAAABpg9avAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4IqM3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c7968c7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(y_train_c,xgb_stacked_train_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
